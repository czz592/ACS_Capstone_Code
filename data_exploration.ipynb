{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5a719f",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook will primarily explore the dataset, and using insights gained from the EDA, experiment with preprocessing steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cfd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_df(df: pd.DataFrame):\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nColumn types:\\n\", df.dtypes.value_counts())\n",
    "    print(f\"\\nConstant columns:\\n{df.nunique()[df.nunique() <= 1]}\\n\")\n",
    "    df.info(verbose=True, show_counts=True, max_cols=None)\n",
    "    print(df.describe(include='all'))\n",
    "\n",
    "def print_unique_values(df: pd.DataFrame):\n",
    "    for col in df.columns:\n",
    "        if col == 'Attack_label' or col == 'Attack_type':\n",
    "            continue\n",
    "        if len(df[col].value_counts()) > 10:\n",
    "            continue\n",
    "        print(\"Unique values of \", col, \":\", df[col].value_counts())\n",
    "\n",
    "def show_target_distribution(df: pd.DataFrame):\n",
    "    sns.countplot(data=df, x='Attack_label')\n",
    "    plt.title(\"Binary Attack Label Distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(df['Attack_label'].value_counts())\n",
    "\n",
    "\n",
    "def plot_correlation_heatmap(df: pd.DataFrame, threshold: float = 0.9):\n",
    "    corr = df.select_dtypes(include='number').corr()\n",
    "    # Identify highly correlated pairs\n",
    "    high_corr = ((corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "                  .stack()\n",
    "                  .reset_index()\n",
    "                  .rename(columns={0: 'correlation'}))\n",
    "                 .query('abs(correlation) > @threshold'))\n",
    "    print(\"Highly correlated features (>|0.9|):\\n\", high_corr)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "    plt.title(\"Feature Correlation Heatmap\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae30174",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./dataset/edge-iiotset/\"\n",
    "\n",
    "normal_path = path + (\"normal/\")\n",
    "attack_path = path + (\"attack/\")\n",
    "eval_path = \"./dataset/edge-iiotset/eval/\"\n",
    "# output_path = \"./dataset/edge-iiotset/eda_output/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43560fa1",
   "metadata": {},
   "source": [
    "## Read, Load, Examine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(eval_path+'DNN-EdgeIIoT-dataset.csv', encoding='utf-8', low_memory=False)\n",
    "df = pd.read_csv(eval_path+'ML-EdgeIIoT-dataset.csv', encoding='utf-8', low_memory=False)\n",
    "\n",
    "# visualise_df(df)\n",
    "plot_correlation_heatmap(df)\n",
    "\n",
    "summarise_df(df)\n",
    "\n",
    "print_unique_values(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27913bc",
   "metadata": {},
   "source": [
    "## Global Preprocessing \n",
    "\n",
    "Dropping irrelevant columns, removing duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d77bc9",
   "metadata": {},
   "source": [
    "### Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdfa683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45d514",
   "metadata": {},
   "source": [
    "### Safe Columns to Drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f147888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols dropped by domain knowledge - safe to drop as they do not contribute\n",
    "safe_to_drop_cols = [\n",
    "    \"frame.time\",\n",
    "    \"ip.src_host\",\n",
    "    \"ip.dst_host\",\n",
    "    \"icmp.unused\",\n",
    "    \"icmp.transmit_timestamp\",\n",
    "    \"http.file_data\",\n",
    "    \"http.request.full_uri\",\n",
    "    \"tcp.options\",\n",
    "    \"tcp.payload\",\n",
    "    \"arp.src.proto_ipv4\",\n",
    "    \"arp.dst.proto_ipv4\",\n",
    "    \"mqtt.msg\",\n",
    "    \"mqtt.msg_decoded_as\",\n",
    "    \"Attack_type\"\n",
    "]\n",
    "\n",
    "dropped_df = df.drop(safe_to_drop_cols, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21edebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine dropped_df\n",
    "\n",
    "summarise_df(dropped_df)\n",
    "print_unique_values(dropped_df)\n",
    "show_target_distribution(dropped_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39369629",
   "metadata": {},
   "source": [
    "### Constant Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "constant_columns = [col for col in dropped_df.columns if dropped_df[col].nunique() == 1]\n",
    "\n",
    "print(f\"Constant columns: {constant_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_counts = defaultdict(int)\n",
    "non_zero_counts = defaultdict(int)\n",
    "value_counts = {col: defaultdict(int) for col in constant_columns}\n",
    "total_rows = 0\n",
    "\n",
    "for path in [normal_path, attack_path]:\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            df = pd.read_csv(file_path, usecols=constant_columns,\n",
    "                             encoding='utf-8', low_memory=False)\n",
    "            total_rows += len(df)\n",
    "            for col in constant_columns:\n",
    "                zero_counts[col] += (df[col] == 0).sum()\n",
    "                non_zero_counts[col] += (df[col] != 0).sum()\n",
    "                for val, count in df[col].value_counts(dropna=True).items():\n",
    "                    value_counts[col][val] += count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in constant_columns:\n",
    "    total_non_zero = non_zero_counts[col]\n",
    "    total_zero = zero_counts[col]\n",
    "    total_unique = len(value_counts[col])\n",
    "    sparsity = total_zero / total_rows\n",
    "    dominant_ratio = max(\n",
    "        value_counts[col].values()) / (total_zero + total_non_zero)\n",
    "\n",
    "    print(f\"{col} — Unique values: {total_unique}, 0-based sparsity: {sparsity:.8%} of {total_rows}, Dominant ratio: {dominant_ratio:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fec4dc",
   "metadata": {},
   "source": [
    "### Sparse Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_columns = [col for col in dropped_df.columns if col not in constant_columns and col !=\n",
    "                  \"Attack_label\" and dropped_df[col].eq(0).sum() >= 0.99]\n",
    "\n",
    "print(f\"Sparse columns: {sparse_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11719c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_counts = defaultdict(int)\n",
    "non_zero_counts = defaultdict(int)\n",
    "value_counts = {col: defaultdict(int) for col in sparse_columns}\n",
    "total_rows = 0\n",
    "\n",
    "for path in [normal_path, attack_path]:\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(path, file)\n",
    "            df = pd.read_csv(file_path, usecols=sparse_columns,\n",
    "                             encoding='utf-8', low_memory=False)\n",
    "            total_rows += len(df)\n",
    "            for col in sparse_columns:\n",
    "                zero_counts[col] += (df[col] == 0).sum()\n",
    "                non_zero_counts[col] += (df[col] != 0).sum()\n",
    "                for val, count in df[col].value_counts(dropna=True).items():\n",
    "                    value_counts[col][val] += count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35392da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sparse_columns:\n",
    "    total_non_zero = non_zero_counts[col]\n",
    "    total_zero = zero_counts[col]\n",
    "    total_unique = len(value_counts[col])\n",
    "    sparsity = total_zero / total_rows\n",
    "    dominant_ratio = max(\n",
    "        value_counts[col].values()) / (total_zero + total_non_zero)\n",
    "\n",
    "    print(f\"{col} — Unique values: {total_unique}, 0-based sparsity: {sparsity:.8%} of {total_rows}, Dominant ratio: {dominant_ratio:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d475cf",
   "metadata": {},
   "source": [
    "## Splitting to Training and Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df966fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "train_df, test_df = train_test_split(dropped_df, test_size=0.2, random_state=42, stratify=dropped_df['Attack_label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5b7a4",
   "metadata": {},
   "source": [
    "## Statistical Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile list of numerical and categorical features\n",
    "# categorical if object or <= 10 unique values\n",
    "\n",
    "categorical_features = []\n",
    "numerical_features = []\n",
    "\n",
    "for col in train_df.columns[:-1]:\n",
    "    if train_df[col].dtype == 'object' or len(train_df[col].unique()) <= 10:\n",
    "        categorical_features.append(col)\n",
    "    else:\n",
    "        numerical_features.append(col)\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Numerical features:\", numerical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ace2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_features:\n",
    "    print(dropped_df.groupby(col)['Attack_label'].mean().sort_values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0d7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preserve_and_clean(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "train_df = preserve_and_clean(train_df, categorical_features)\n",
    "test_df = preserve_and_clean(test_df, categorical_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605bc1ac",
   "metadata": {},
   "source": [
    "### Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048efb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numerical features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_df[numerical_features] = scaler.fit_transform(train_df[numerical_features])\n",
    "test_df[numerical_features] = scaler.transform(test_df[numerical_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48ec07",
   "metadata": {},
   "source": [
    "### Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot = OneHotEncoder()\n",
    "train_df[categorical_features] = train_df[categorical_features].apply(onehot.fit_transform)\n",
    "\n",
    "test_df[categorical_features] = test_df[categorical_features].apply(onehot.transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_df(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afc1e7",
   "metadata": {},
   "source": [
    "## Write to File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save into preprocessed/\n",
    "# train_df.to_csv(\"./dataset/edge-iiotset/preprocessed/train.csv\", index=False)\n",
    "# test_df.to_csv(\"./dataset/edge-iiotset/preprocessed/test.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
